"""
Test du modÃ¨le NER spÃ©cialisÃ© recettes : edwardjross/xlm-roberta-base-finetuned-recipe-all
Ce modÃ¨le dÃ©compose une ligne d'ingrÃ©dient en : NAME, QUANTITY, UNIT, STATE, SIZE, TEMP, DF
F1 = 0.967 sur le test set

Usage: python test_recipe_ner.py
"""

from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
import json
from collections import defaultdict


def load_model():
    """Charge le modÃ¨le NER spÃ©cialisÃ© recettes."""
    print("Chargement du modÃ¨le edwardjross/xlm-roberta-base-finetuned-recipe-all...")
    print("(premier lancement = tÃ©lÃ©chargement ~1GB, ensuite c'est en cache)\n")

    model_name = "edwardjross/xlm-roberta-base-finetuned-recipe-all"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForTokenClassification.from_pretrained(model_name)

    ner_pipeline = pipeline(
        "token-classification",
        model=model,
        tokenizer=tokenizer,
        aggregation_strategy="simple",  # Regroupe les sous-tokens
    )
    print("ModÃ¨le chargÃ© !\n")
    return ner_pipeline


def parse_ingredient(ner_pipeline, ingredient_text: str) -> dict:
    """Parse un ingrÃ©dient et retourne les entitÃ©s dÃ©tectÃ©es."""
    results = ner_pipeline(ingredient_text)

    # Regrouper par type d'entitÃ©
    entities = defaultdict(list)
    for entity in results:
        tag = entity["entity_group"]
        word = entity["word"].strip()
        score = entity["score"]
        entities[tag].append({"text": word, "score": round(score, 4)})

    return {
        "input": ingredient_text,
        "entities": dict(entities),
        "raw": [
            {
                "tag": r["entity_group"],
                "text": r["word"].strip(),
                "score": round(r["score"], 4),
            }
            for r in results
        ],
    }


def display_result(result: dict):
    """Affiche le rÃ©sultat de maniÃ¨re lisible."""
    print(f"  Input: \"{result['input']}\"")

    tag_colors = {
        "NAME": "ğŸŸ¢",
        "QUANTITY": "ğŸ”µ",
        "UNIT": "ğŸŸ¡",
        "STATE": "ğŸŸ ",
        "SIZE": "ğŸŸ£",
        "TEMP": "ğŸ”´",
        "DF": "âšª",
    }

    for tag, items in result["entities"].items():
        icon = tag_colors.get(tag, "âš«")
        values = ", ".join(
            [f"{item['text']} ({item['score']:.1%})" for item in items]
        )
        print(f"    {icon} {tag:10s} â†’ {values}")
    print()


def main():
    ner = load_model()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST 1 : IngrÃ©dients classiques en anglais
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("=" * 70)
    print("TEST 1 : IngrÃ©dients classiques (anglais)")
    print("=" * 70)

    english_ingredients = [
        "2 cups all-purpose flour",
        "1/2 teaspoon fresh thyme, minced",
        "3 large eggs, beaten",
        "150 g unsalted butter, melted",
        "1 pound boneless skinless chicken breast, cut into cubes",
        "2 tablespoons extra virgin olive oil",
        "1 (14 oz) can diced tomatoes",
        "3 cloves garlic, finely minced",
        "1/4 cup freshly squeezed lemon juice",
        "salt and pepper to taste",
    ]

    for ing in english_ingredients:
        result = parse_ingredient(ner, ing)
        display_result(result)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST 2 : IngrÃ©dients en franÃ§ais (le modÃ¨le est XLM = multilingue)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("=" * 70)
    print("TEST 2 : IngrÃ©dients en franÃ§ais (test multilingue)")
    print("=" * 70)

    french_ingredients = [
        "200 g de farine",
        "3 cuillÃ¨res Ã  soupe d'huile d'olive",
        "150 g de beurre doux fondu",
        "1 kg de pommes de terre Ã  chair ferme",
        "4 gousses d'ail Ã©mincÃ©es",
        "2 oignons moyens finement ciselÃ©s",
        "50 cl de crÃ¨me fraÃ®che Ã©paisse",
        "1 bouquet de persil plat frais hachÃ©",
        "sel et poivre du moulin",
        "500 g de filet de saumon frais sans peau",
    ]

    for ing in french_ingredients:
        result = parse_ingredient(ner, ing)
        display_result(result)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST 3 : Cas difficiles / piÃ¨ges
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("=" * 70)
    print("TEST 3 : Cas difficiles et piÃ¨ges")
    print("=" * 70)

    tricky_ingredients = [
        # QuantitÃ© vague
        "a pinch of saffron threads",
        # Deux ingrÃ©dients sur une ligne
        "salt and freshly ground black pepper",
        # TempÃ©rature
        "1 cup warm milk (about 110Â°F)",
        # Taille + Ã©tat
        "2 large ripe avocados, peeled and diced",
        # Format bizarre
        "1-2 tablespoons honey, or to taste",
        # IngrÃ©dient complexe
        "1 (400g) block extra-firm tofu, drained and pressed",
        # Frais/sec
        "2 teaspoons dried oregano",
        "1/4 cup fresh basil leaves, torn",
    ]

    for ing in tricky_ingredients:
        result = parse_ingredient(ner, ing)
        display_result(result)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST 4 : Simulation de cross-check avec un LLM
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("=" * 70)
    print("TEST 4 : Simulation de cross-check NER vs LLM")
    print("=" * 70)

    # Simulons ce que Claude pourrait produire vs ce que le NER dÃ©tecte
    simulated_checks = [
        {
            "source_text": "150g de beurre doux",
            "llm_output": {
                "name": "beurre doux",
                "quantity": 150,
                "unit": "g",
                "state": "fondu",  # â† HALLUCINATION : "fondu" n'est pas dans le texte
            },
        },
        {
            "source_text": "3 eggs",
            "llm_output": {
                "name": "eggs",
                "quantity": 3,
                "unit": None,
                "state": None,
            },
        },
        {
            "source_text": "2 tablespoons olive oil",
            "llm_output": {
                "name": "extra virgin olive oil",  # â† HALLUCINATION : "extra virgin" inventÃ©
                "quantity": 2,
                "unit": "tablespoons",
                "state": None,
            },
        },
        {
            "source_text": "1 onion, finely chopped",
            "llm_output": {
                "name": "onion",
                "quantity": 1,
                "unit": None,
                "state": "finely chopped",  # â† CORRECT : c'est dans le texte
            },
        },
    ]

    for check in simulated_checks:
        ner_result = parse_ingredient(ner, check["source_text"])
        llm = check["llm_output"]
        ner_entities = ner_result["entities"]

        print(f"  Source: \"{check['source_text']}\"")
        print(f"  LLM dit:  name={llm['name']}, qty={llm['quantity']}, unit={llm['unit']}, state={llm['state']}")

        # Extraire ce que le NER a trouvÃ©
        ner_name = " ".join([e["text"] for e in ner_entities.get("NAME", [])])
        ner_qty = " ".join([e["text"] for e in ner_entities.get("QUANTITY", [])])
        ner_unit = " ".join([e["text"] for e in ner_entities.get("UNIT", [])])
        ner_state = " ".join([e["text"] for e in ner_entities.get("STATE", [])])

        print(f"  NER dit:  name={ner_name or 'âˆ…'}, qty={ner_qty or 'âˆ…'}, unit={ner_unit or 'âˆ…'}, state={ner_state or 'âˆ…'}")

        # DÃ©tecter les divergences
        issues = []
        if llm.get("state") and not ner_state:
            issues.append(f"âš ï¸  HALLUCINATION probable : LLM dit state=\"{llm['state']}\" mais NER ne dÃ©tecte rien")
        if llm.get("name") and ner_name and llm["name"].lower() != ner_name.lower():
            # VÃ©rifier si le LLM a ajoutÃ© des mots
            llm_words = set(llm["name"].lower().split())
            ner_words = set(ner_name.lower().split())
            added = llm_words - ner_words
            if added:
                issues.append(f"âš ï¸  HALLUCINATION probable : LLM ajoute \"{' '.join(added)}\" au nom")

        if issues:
            for issue in issues:
                print(f"  {issue}")
        else:
            print("  âœ… CohÃ©rent â€” pas de divergence dÃ©tectÃ©e")
        print()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RÃ©sumÃ©
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("=" * 70)
    print("RÃ‰SUMÃ‰")
    print("=" * 70)
    print("""
Le modÃ¨le NER spÃ©cialisÃ© recettes :
- Parse les ingrÃ©dients en composants (nom, quantitÃ©, unitÃ©, Ã©tat, taille, tempÃ©rature)
- F1 = 0.967 â†’ se trompe dans ~3% des cas
- DÃ©terministe : mÃªme input = mÃªme output, toujours
- Pas d'hallucination possible (il classifie, il n'invente pas)
- Multilingue (XLM-RoBERTa) â†’ test en franÃ§ais possible

UtilisÃ© en cross-check avec un LLM :
- Si le LLM dit "fondu" mais le NER ne voit pas "fondu" dans le texte â†’ flag
- Si le LLM dit "extra virgin" mais le NER ne voit que "olive oil" â†’ flag
- ComplÃ©mentaire : le NER attrape ce que le LLM invente
    """)


if __name__ == "__main__":
    main()
